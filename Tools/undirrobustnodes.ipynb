{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9aec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from scipy.sparse import load_npz\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# FOLDERS = [\"AIRWAY_HYPERREACTIVITY/\", \"ARTHRITIS/\", \n",
    "#  \"CROHNS/\", \"DIABETES_II/\", \"HEART_FAILURE/\", \"HIV/\", \"NEOPLASM_BREAST/\"]\n",
    "\n",
    "FOLDER = \"CROHNS/\"\n",
    "DGIDB_DIRECTORY = \"../Gen_Hypergraph/output/\" + FOLDER\n",
    "DGIDB_CONVERGED_VECTOR_PATH = \"../Methods/output/\" + FOLDER + \"DGIDB_vector.npy\"\n",
    "MSIGDB_DIRECTORY = \"../Gen_Hypergraph/output/MSigDB_FULL/\"\n",
    "restart_prob = 0.2  # Restart probability (theta)\n",
    "num_iterations = 10  # Number of iterationsh\n",
    "\n",
    "OUTPUT_FOLDER = \"./robustnodes/DIABETES_II/\"\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "disease = \"type 2 diabetes mellitus\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "369b54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the JSON file and load its content into a dictionary\n",
    "with open(DGIDB_DIRECTORY + \"gene_to_index.json\", \"r\") as file:\n",
    "    dgidb = json.load(file)\n",
    "with open(MSIGDB_DIRECTORY + \"gene_to_index.json\", \"r\") as file:\n",
    "    msigdb = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "349a439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Jump probability for matching genes\n",
    "w = 1\n",
    "\n",
    "# Number of genes (assuming they are both of same size or matchable)\n",
    "num_genes_dgidb = len(dgidb)\n",
    "num_genes_msigdb = len(msigdb)\n",
    "\n",
    "# Initialize the inter-layer matrix (D) with zeros\n",
    "D = np.zeros((num_genes_dgidb, num_genes_msigdb))\n",
    "i = 0\n",
    "# Build the inter-layer matrix (D)\n",
    "for gene_dgidb, idx_dgidb in dgidb.items():\n",
    "    # If the gene exists in both gene-to-index mappings\n",
    "    if gene_dgidb in msigdb:      \n",
    "        idx_msigdb = msigdb[gene_dgidb]\n",
    "        D[idx_dgidb, idx_msigdb] = w  # Set jump probability\n",
    "        i += 1\n",
    "rows_with_high_sum = np.where(D.sum(axis=1) > 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bca42f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load matrices\n",
    "MSIGDB_weighted_matrix = load_npz(MSIGDB_DIRECTORY + \"hypergraph_incidence_matrix_weighted.npz\")\n",
    "MSIGDB_binary_matrix = load_npz(MSIGDB_DIRECTORY + \"hypergraph_incidence_matrix_binary.npz\")\n",
    "DGIDB_binary_matrix = load_npz(DGIDB_DIRECTORY + \"hypergraph_incidence_matrix_binary.npz\")\n",
    "DGIDB_vector =  np.load(DGIDB_CONVERGED_VECTOR_PATH)\n",
    "\n",
    "num_genes_MSIGDB = MSIGDB_binary_matrix.shape[0]  # Number of genes in MSIGDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc57fe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b42d31d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGIDB full vector calculation: 100%|██████████| 21981/21981 [17:44<00:00, 20.64it/s]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "dgidb_vector_complete = np.zeros(num_genes_MSIGDB)\n",
    "\n",
    "for gene in tqdm(range(num_genes_MSIGDB), desc=\"DGIDB full vector calculation\"):\n",
    "    # Intra-hypergraph transitions in MSIGDB (moving within MSIGDB)\n",
    "    connected_pathways = MSIGDB_binary_matrix[gene, :].nonzero()[1]  # Nonzero columns in MSIGDB binary matrix\n",
    "\n",
    "    if len(connected_pathways) == 0:\n",
    "        continue  # Skip if no pathways are found\n",
    "\n",
    "    for pathway in connected_pathways:\n",
    "        # Find genes connected to the selected pathway (weighted transition in MSIGDB)\n",
    "        connected_genes = MSIGDB_weighted_matrix[:, pathway].toarray().flatten()\n",
    "        neighbor_genes = np.where(connected_genes > 0)[0]  # Get genes with nonzero weight\n",
    "\n",
    "        # Check if the current gene has a DGIDB connection\n",
    "        dgidb_gene = np.where(D[:, gene] > 0)[0]  # Find DGIDB neighbors of the current MSIGDB gene\n",
    "        if len(dgidb_gene) == 1:\n",
    "            dgidb_drugs = DGIDB_binary_matrix[dgidb_gene[0], :].nonzero()[1]\n",
    "            neighbor_genes_set = set()  # To avoid duplicates\n",
    "        \n",
    "            for drug in dgidb_drugs:\n",
    "                # Get genes connected through the same drug (edge)\n",
    "                connected_genes = DGIDB_binary_matrix[:, drug].toarray().flatten()\n",
    "                neighbor_genes = np.where(connected_genes > 0)[0]\n",
    "                # Add unique neighbors to the set\n",
    "                neighbor_genes_set.update(neighbor_genes)\n",
    "\n",
    "            # Sum contributions from unique DGIDB neighbors\n",
    "            if len(neighbor_genes_set) > 0:\n",
    "                neighbor_genes_list = list(neighbor_genes_set)\n",
    "                dgidb_contribution = np.sum(DGIDB_vector[neighbor_genes_list])  # Sum unique contributions\n",
    "                dgidb_vector_complete[gene] += dgidb_contribution  # Store in the complete vector\n",
    "\n",
    "# Normalize dgidb_vector_complete to avoid overflow\n",
    "dgidb_vector_complete /= np.sum(dgidb_vector_complete) if np.sum(dgidb_vector_complete) > 0 else 1\n",
    "dgidb_vector_complete = torch.from_numpy(dgidb_vector_complete).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6d9c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyper_randomwalk_torch(DGIDB_binary_matrix, DGIDB_vector, MSIGDB_weighted_matrix, MSIGDB_binary_matrix, D, restart_prob, num_iterations, P, dgidb_vector_complete, v0_sample):\n",
    "    vi = v0_sample.clone()\n",
    "    teleport_torch = v0_sample.clone()\n",
    "    distance_list = []\n",
    "    for k in range(num_iterations):\n",
    "        print(f\"Iteration {k + 1}\")\n",
    "        vj = vi.clone()\n",
    "\n",
    "        # Vectorized transition step\n",
    "        # Resulting shape will be (n, n)\n",
    "\n",
    "        # Step 2: Normalize P by dividing by the sum of each column (with a small constant to avoid division by zero)\n",
    "        P = P / (P.sum(dim=0, keepdim=True) + 1e-9)\n",
    "        vi_new = torch.matmul(P.T.float(), vj.float())  # Transition from vj to vi_new using matrix multiplication\n",
    "\n",
    "        # Normalize and combine\n",
    "        vi_new = vi_new / (vi_new.sum() + 1e-9)\n",
    "        \n",
    "        vi = restart_prob * vi_new.T + (1 - restart_prob) * teleport_torch + dgidb_vector_complete\n",
    "\n",
    "        distance = torch.sum(torch.abs(vj - vi)).item()\n",
    "        distance_list.append(distance)\n",
    "\n",
    "\n",
    "    importance_scores = torch.argsort(vi, descending=True)\n",
    "    importance_values = vi[importance_scores]\n",
    "\n",
    "    return {\n",
    "        \"Importance\": list(zip(importance_scores.tolist(), importance_values.tolist())),\n",
    "        \"Distance\": distance_list\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be9ded67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Top Indices by Importance:\n",
      "Index 13090: 0.094853\n",
      "Index 9287: 0.093089\n",
      "Index 14504: 0.073376\n",
      "Index 10310: 0.072723\n",
      "Index 12118: 0.066522\n",
      "Index 9914: 0.046309\n",
      "Index 12033: 0.045071\n",
      "Index 6813: 0.044140\n",
      "Index 14984: 0.039681\n",
      "Index 9794: 0.033483\n",
      "\n",
      "Distance per Iteration:\n",
      "[1.0000007461530913, 0.09796130485483445, 0.0012409969931468368, 1.9727754988707602e-05, 4.050161805935204e-07, 5.4700649343430996e-08, 6.05832610744983e-08, 5.8225850807502866e-08, 4.721368895843625e-08, 4.757748683914542e-08]\n"
     ]
    }
   ],
   "source": [
    "# result = get_hyper_randomwalk(DGIDB_binary_matrix, DGIDB_vector, MSIGDB_weighted_matrix, MSIGDB_binary_matrix, D, restart_prob, num_iterations)\n",
    "# Print results\n",
    "MSIGDB_weighted = torch.tensor(MSIGDB_weighted_matrix.toarray(), dtype=torch.float32, device=device)\n",
    "MSIGDB_binary = torch.tensor(MSIGDB_binary_matrix.toarray(), dtype=torch.float32, device=device)\n",
    "DGIDB_binary = torch.tensor(DGIDB_binary_matrix.toarray(), dtype=torch.float32, device=device)\n",
    "# DGIDB_vector = torch.tensor(DGIDB_vector, dtype=torch.float32, device=device)\n",
    "# D = torch.tensor(D, dtype=torch.float32, device=device)\n",
    "\n",
    "num_genes_MSIGDB = MSIGDB_binary.shape[0]\n",
    "v0 = torch.full((num_genes_MSIGDB,), 1.0 / num_genes_MSIGDB, dtype=torch.float32, device=device)\n",
    "teleport = v0.clone()\n",
    "P = MSIGDB_weighted @ MSIGDB_weighted.T\n",
    "v0 = torch.full((num_genes_MSIGDB,), 1.0 / num_genes_MSIGDB, dtype=torch.float32, device=device)\n",
    "result = get_hyper_randomwalk_torch(DGIDB_binary_matrix, DGIDB_vector, MSIGDB_weighted_matrix, MSIGDB_binary_matrix, D, restart_prob, num_iterations, P, dgidb_vector_complete, v0)\n",
    "print(\"Top Indices by Importance:\")\n",
    "for index, score in result[\"Importance\"][:10]:\n",
    "    print(f\"Index {index}: {score:.6f}\")\n",
    "\n",
    "print(\"\\nDistance per Iteration:\")\n",
    "print(result[\"Distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d04ed9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the JSON data from the file\n",
    "with open(MSIGDB_DIRECTORY + 'gene_to_index.json', 'r') as file:\n",
    "    gene_to_index = json.load(file)\n",
    "\n",
    "# Invert the dictionary to map indices back to genes\n",
    "index_to_gene = {v: k for k, v in gene_to_index.items()}\n",
    "# human_gene2refseq = NCBI_INFO[NCBI_INFO['#tax_id'] == 9606]\n",
    "# id_to_gene_claim = pd.Series(human_gene2refseq.Symbol.values, index=human_gene2refseq.GeneID).to_dict()\n",
    "with open(\"../Methods/id_to_gene_claim.json\", \"r\") as f:\n",
    "    id_to_gene_claim = json.load(f)\n",
    "\n",
    "def get_gene_claim_name(ncbi_gene_id):\n",
    "    ncbi_gene_id = int(ncbi_gene_id)\n",
    "    result = id_to_gene_claim[str(ncbi_gene_id)]\n",
    "    if result:\n",
    "        return result\n",
    "    else:\n",
    "        return \"Gene name not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab19c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(result[\"Importance\"], columns=['Index', 'Score'])\n",
    "results_df[\"ncbi_gene_id\"] = results_df[\"Index\"].apply(index_to_gene.get)\n",
    "results_df[\"claim_name\"] = results_df[\"ncbi_gene_id\"].apply(get_gene_claim_name)\n",
    "results_df.to_csv(OUTPUT_FOLDER + \"baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aec16459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm difference between P_PERTURBED and P: 0.8921632766723633\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8949627876281738\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8935789465904236\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8974792957305908\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.897468626499176\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8918126821517944\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8934016823768616\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.9004422426223755\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8974258303642273\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8979145288467407\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8943232893943787\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8977358341217041\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8975017666816711\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8931811451911926\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8979794383049011\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8945189714431763\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8979201316833496\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.891067624092102\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8948871493339539\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Frobenius norm difference between P_PERTURBED and P: 0.8942322731018066\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "# Original uniform prior (used as mean of Dirichlet)\n",
    "K = num_genes_MSIGDB\n",
    "\n",
    "v0_base = torch.full((K,), 1.0 / K, dtype=torch.float32, device=device)\n",
    "def perturb_matrix(matrix, fraction=0.1, amount=0.1, device=None):\n",
    "    # Convert to dense NumPy array\n",
    "    if hasattr(matrix, \"toarray\"):\n",
    "        matrix_np = matrix.toarray()\n",
    "    else:\n",
    "        matrix_np = np.array(matrix)\n",
    "\n",
    "    # Find non-zero indices\n",
    "    nonzero_indices = np.argwhere(matrix_np > 0)\n",
    "    num_edges = len(nonzero_indices)\n",
    "\n",
    "    if num_edges == 0:\n",
    "        raise ValueError(\"Matrix has no non-zero entries to perturb.\")\n",
    "\n",
    "    # Calculate perturbation value\n",
    "    mean_weight = matrix_np[matrix_np > 0].mean()\n",
    "    perturb_value = amount * mean_weight\n",
    "\n",
    "    # Randomly select indices to perturb\n",
    "    num_to_perturb = max(1, int(fraction * num_edges))\n",
    "    selected_indices = random.sample(list(nonzero_indices), num_to_perturb)\n",
    "\n",
    "    # Apply perturbation\n",
    "    for i, j in selected_indices:\n",
    "        matrix_np[i, j] += perturb_value\n",
    "\n",
    "    # Convert to PyTorch tensor\n",
    "    perturbed_tensor = torch.tensor(matrix_np, dtype=torch.float32, device=device)\n",
    "\n",
    "    return perturbed_tensor\n",
    "\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    # Convert sparse matrices to dense (or use PyTorch sparse support if memory limited)\n",
    "    MSIGDB_binary = torch.tensor(MSIGDB_binary_matrix.toarray(), dtype=torch.float32, device=device)\n",
    "    DGIDB_binary = torch.tensor(DGIDB_binary_matrix.toarray(), dtype=torch.float32, device=device)\n",
    "    # DGIDB_vector = torch.tensor(DGIDB_vector, dtype=torch.float32, device=device)\n",
    "    # D = torch.tensor(D, dtype=torch.float32, device=device)\n",
    "\n",
    "    num_genes_MSIGDB = MSIGDB_binary.shape[0]\n",
    "\n",
    "    MSIGDB_weighted_perturbed = perturb_matrix(MSIGDB_weighted_matrix, fraction=0.1, amount=1, device=device)\n",
    "    P_PERTURBED = MSIGDB_weighted_perturbed @ MSIGDB_weighted_perturbed.T\n",
    "    diff = torch.norm(P_PERTURBED - P, p='fro')  # Frobenius norm\n",
    "    print(\"Frobenius norm difference between P_PERTURBED and P:\", diff.item())\n",
    "\n",
    "    # Call your method with sampled v0\n",
    "    result = get_hyper_randomwalk_torch(\n",
    "        DGIDB_binary_matrix,\n",
    "        DGIDB_vector,\n",
    "        MSIGDB_weighted_matrix,\n",
    "        MSIGDB_binary_matrix,\n",
    "        D,\n",
    "        restart_prob,\n",
    "        num_iterations,\n",
    "        P_PERTURBED,\n",
    "        dgidb_vector_complete,\n",
    "        v0_base\n",
    "    )\n",
    "    results_df = pd.DataFrame(result[\"Importance\"], columns=['Index', 'Score'])\n",
    "    results_df[\"ncbi_gene_id\"] = results_df[\"Index\"].apply(index_to_gene.get)\n",
    "    results_df[\"claim_name\"] = results_df[\"ncbi_gene_id\"].apply(get_gene_claim_name)\n",
    "    results_df.to_csv(OUTPUT_FOLDER + f\"robustnodes_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53de44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../Data/df_score_as_value.tsv\", sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "86e396d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df[disease].notna()]\n",
    "filtered_df = filtered_df.sort_values(by=disease, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "649e6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_agreement_score(L1_scores: dict, L1_ranking: list, L2_ranking: list, k: int = None) -> float:\n",
    "    if k is None:\n",
    "        k = len(L2_ranking)\n",
    "    \n",
    "    total = 0\n",
    "    # Assign proxy scores to L2 based on inverse rank (1-based)\n",
    "    for idx, item in enumerate(L2_ranking[:k]):\n",
    "        if item not in L1_scores:\n",
    "            continue  # skip items not in L1\n",
    "        \n",
    "        score_L1 = L1_scores[L1_ranking[idx]]\n",
    "        score_L2 = L1_scores[item] \n",
    "\n",
    "        if score_L1 == 0 or score_L2 == 0:\n",
    "            continue  # avoid division by zero\n",
    "        ratio = min(score_L2 / score_L1, score_L1 / score_L2)\n",
    "        total += ratio\n",
    "\n",
    "    return total / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ad158247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 96.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576, 0.16846947565732576]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "baseline = pd.read_csv(os.path.join(OUTPUT_FOLDER, \"baseline.csv\"))\n",
    "baselineGenes = baseline[\"claim_name\"][:10]\n",
    "\n",
    "pattern = re.compile(r\"robustnodes_(\\d+)\\.csv\")\n",
    "csv_files = [f for f in os.listdir(OUTPUT_FOLDER) if pattern.match(f)]\n",
    "wmra_scores = []\n",
    "k = 10\n",
    "\n",
    "for fname in tqdm(sorted(csv_files, key=lambda f: int(pattern.match(f).group(1)))):\n",
    "    drichletNum = int(pattern.match(fname).group(1))\n",
    "    drichletSample = pd.read_csv(os.path.join(OUTPUT_FOLDER, fname))\n",
    "\n",
    "    WMRA = ranking_agreement_score(filtered_df[disease], filtered_df[disease].index, drichletSample[\"claim_name\"][:k], k)\n",
    "    wmra_scores.append(WMRA)\n",
    "\n",
    "\n",
    "print(wmra_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7249f659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.1685, Std Dev: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "mean = statistics.mean(wmra_scores)\n",
    "stdev = statistics.stdev(wmra_scores)\n",
    "\n",
    "print(f\"Mean: {mean:.4f}, Std Dev: {stdev:.4f}\")\n",
    "output_path = os.path.join(OUTPUT_FOLDER, \"final.txt\")\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(f\"Mean: {mean:.4f}, Std Dev: {stdev:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchdgivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
