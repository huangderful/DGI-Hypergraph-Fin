{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e3a4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from scipy.sparse import load_npz\n",
    "import pandas as pd\n",
    "import os\n",
    "FOLDER = \"DGIDB_NEOPLASM_BREAST/\"\n",
    "HYPERGRAPH_DIRECTORY = \"../Gen_Hypergraph/output/\" + FOLDER\n",
    "OUTPUT_FOLDER = \"./output/\" + FOLDER \n",
    "DGIDB = pd.read_csv(\"../Data/DGIDB/DrugToGene.tsv\", sep=\"\\t\")\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "restart_prob = 0.2  # Restart probability (theta)\n",
    "num_iterations = 10  # Number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b5ffb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_matrix = load_npz(HYPERGRAPH_DIRECTORY + \"hypergraph_incidence_matrix_binary.npz\")\n",
    "weighted_matrix = load_npz(HYPERGRAPH_DIRECTORY + \"hypergraph_incidence_matrix_weighted.npz\")\n",
    "\n",
    "num_genes = binary_matrix.shape[0]  # Number of genes\n",
    "num_drugs = binary_matrix.shape[1]  # Number of drugs\n",
    "\n",
    "# Initialize probability vectors\n",
    "v0 = np.ones(num_genes) / num_genes  # Initial uniform probability\n",
    "teleport = np.ones(num_genes) / num_genes  # Restart probability vector\n",
    "\n",
    "def get_hyper_randomwalk(binary_matrix, weighted_matrix, restart_prob, num_iterations):\n",
    "    \"\"\"Performs a hypergraph-based random walk with restart with proper normalization.\"\"\"\n",
    "    vi = v0.copy()  # Start with uniform probability\n",
    "    distance_list = []\n",
    "\n",
    "    for k in range(num_iterations):\n",
    "        print(f\"{k+1} iteration\")\n",
    "\n",
    "        # Store previous probability vector\n",
    "        vj = vi.copy()\n",
    "\n",
    "        # Initialize new probability vector\n",
    "        vi_new = np.zeros(num_genes)\n",
    "\n",
    "        for gene in range(num_genes):\n",
    "            # Find drugs (hyperedges) connected to the current gene\n",
    "            connected_drugs = binary_matrix[gene, :].nonzero()[1]  # Nonzero columns\n",
    "\n",
    "            if len(connected_drugs) == 0:\n",
    "                continue  # Skip if no drugs are found\n",
    "\n",
    "            # Collect probabilities from neighbors\n",
    "            prob_sum = 0\n",
    "            for drug in connected_drugs:\n",
    "                # Find genes connected to the selected drug (via weights)\n",
    "                connected_genes = weighted_matrix[:, drug].toarray().flatten()\n",
    "                neighbor_genes = np.where(connected_genes > 0)[0]  # Get genes with nonzero weight\n",
    "\n",
    "                if len(neighbor_genes) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Normalize weights\n",
    "                weights = connected_genes[neighbor_genes]\n",
    "                weight_sum = np.sum(weights)\n",
    "                if weight_sum > 0:\n",
    "                    weights /= weight_sum  # Normalize to sum to 1\n",
    "\n",
    "                # Transition probability contribution\n",
    "                prob_sum += np.sum(weights * vj[neighbor_genes])  \n",
    "\n",
    "            vi_new[gene] = prob_sum  # Update probability for the gene\n",
    "\n",
    "        # Normalize vi_new to avoid overflow\n",
    "        vi_new /= np.sum(vi_new) if np.sum(vi_new) > 0 else 1\n",
    "\n",
    "        # Apply restart probability\n",
    "        vi = restart_prob * vi_new + (1 - restart_prob) * teleport\n",
    "\n",
    "        # Calculate distance\n",
    "        distance = np.sum(np.abs(vj - vi))\n",
    "        distance_list.append(distance)\n",
    "\n",
    "    original = vi\n",
    "    # Sort importance scores in descending order\n",
    "    importance_scores = np.argsort(vi)[::-1]\n",
    "    importance_values = vi[importance_scores]\n",
    "\n",
    "    # Return importance scores and distance values\n",
    "    return {\"Importance\": list(zip(importance_scores, importance_values)), \"Distance\": distance_list, \"unsorted\": original}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f100f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iteration\n",
      "2 iteration\n",
      "3 iteration\n",
      "4 iteration\n",
      "5 iteration\n",
      "6 iteration\n",
      "7 iteration\n",
      "8 iteration\n",
      "9 iteration\n",
      "10 iteration\n",
      "Top Indices by Importance:\n",
      "Index 364: 0.002598\n",
      "Index 56: 0.002443\n",
      "Index 216: 0.001937\n",
      "Index 183: 0.001711\n",
      "Index 821: 0.001706\n",
      "Index 53: 0.001445\n",
      "Index 251: 0.001445\n",
      "Index 27: 0.001422\n",
      "Index 300: 0.001408\n",
      "Index 658: 0.001357\n",
      "\n",
      "Distance per Iteration:\n",
      "[0.35341432760787606, 0.019550141197298383, 0.005287998534421963, 0.0016093878942900525, 0.0005455201090555145, 0.00020375258754663355, 7.840489800299392e-05, 3.066825866072801e-05, 1.2113100382427587e-05, 4.807507626255548e-06]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run the random walk\n",
    "result = get_hyper_randomwalk(binary_matrix, weighted_matrix, restart_prob, num_iterations)\n",
    "\n",
    "# Print results\n",
    "print(\"Top Indices by Importance:\")\n",
    "for index, score in result[\"Importance\"][:10]:\n",
    "    print(f\"Index {index}: {score:.6f}\")\n",
    "\n",
    "print(\"\\nDistance per Iteration:\")\n",
    "print(result[\"Distance\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5be0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON data from the file\n",
    "with open(HYPERGRAPH_DIRECTORY + 'gene_to_index.json', 'r') as file:\n",
    "    gene_to_index = json.load(file)\n",
    "\n",
    "# Invert the dictionary to map indices back to genes\n",
    "index_to_gene = {v: k for k, v in gene_to_index.items()}\n",
    "def get_gene_claim_name(ncbi_gene_id):\n",
    "    ncbi_gene_id = int(ncbi_gene_id)\n",
    "    result = DGIDB[(DGIDB['ncbi_gene_id']) == ncbi_gene_id]\n",
    "    if not result.empty:\n",
    "        return result['gene_name'].values[0]\n",
    "    else:\n",
    "        return \"Gene name not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "118b2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(result[\"Importance\"], columns=['Index', 'Score'])\n",
    "results_df[\"ncbi_gene_id\"] = results_df[\"Index\"].apply(index_to_gene.get)\n",
    "results_df[\"claim_name\"] = results_df[\"ncbi_gene_id\"].apply(get_gene_claim_name)\n",
    "results_df.to_csv(OUTPUT_FOLDER + \"single_layer_rwr_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa59cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(OUTPUT_FOLDER + 'DGIDB_vector.npy', result[\"unsorted\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
